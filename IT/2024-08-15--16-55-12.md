nn.functional/exp/nn.functional 是PyTorch中一个重要的模块，它包含了许多用于构建神经网络的函数。与nn.Module 不同，nn.functional 中的函数不具有可学习的参数。这些函数通常用于执行各种非线性操作、损失函数、激活函数等。--------常用的nn.functional 函数1. 激活函数激活函数是神经网络中的关键组件，它们引入非线性性，使网络能够拟合复杂的数据。以下是一些常见的激活函数：1.1 ReLU（Rectified Linear Unit）ReLU是一种简单而有效的激活函数，它将输入值小于零的部分设为零，大于零的部分保持不变。它的数学表达式如下：1.2 SigmoidSigmoid函数将输入值映射到0和1之间，常用于二分类问题的输出层。它的数学表达式如下：1.3 Tanh（双曲正切）Tanh函数将输入值映射到-1和1之间，它具有零中心化的特性，通常在循环神经网络中使用。